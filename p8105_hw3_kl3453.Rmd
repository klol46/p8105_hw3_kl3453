---
title: "HW3: Markdown file"
author: "Kevin Liu"
date: "2023-09-30"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem # 1

```{r}
library(p8105.datasets)
data("instacart")
instacart = 
  instacart |> 
  as_tibble()
```


##  Write a short description of the dataset, 

...noting the size and structure of the data, describing some key variables, and giving illstrative examples of observations. 

* The dataset instacart contains `r count(instacart)` observations and `r ncol(instacart)` variables.

* The dataset describes some form of online ordering system that keeps track of what is purchase in one order, how many, and what product as well as where the product is located by store department and aisle. 

* The dataset has many repeating rows for the same order and thus untidy, in the long form.

* Some key varaibles include the order_id (perhaps the designation for a certain shopper's order), product_id (what the shopper ordered), user_id (designation for the shopper), department (the store department where the item is located), and aisle (the store aisle where the item is located).

* For example, here is the order for shopper `r instacart$user_id[1]` with their order id `r instacart$order_id[1]`. 

```{r}
instacart |> 
  select(product_id, order_id, user_id, product_name, aisle, department) |> 
  head(8)
```

* There are `r instacart |> select(product_id) |> distinct() |> count()` products from `r instacart |> select(user_id, order_id) |> distinct() |> count()` orders from `r instacart |> select(user_id) |> distinct() |> count()` distinct users.

## Then, do or answer the following:

### How many aisles are there, and which aisles are the most items ordered from?

* There are `r instacart |> select(aisle) |>  distinct() |> count()` aisles.

The aisles that are the most ordered are:

```{r}
instacart |> 
  count(aisle) |> 
  arrange(desc(n)) |>
  head(3)
```

### Make a plot that...
shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r}
instacart |> 
  count(aisle) |> 
  filter(n > 10000) |> 
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

### Make a table...
showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r}
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable()
```

### Make a table...
showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r}
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour) |>
  knitr::kable(digits = 2)
```

# Problem #2

```{r}
#Import brfss data and convert into tibble dataframe
data("brfss_smart2010")
brfss_smart2010 = 
  brfss_smart2010 |> 
  as_tibble()
```

### __First__, do some data cleaning:

* format the data to use appropriate variable names;

```{r}
#COnvert variable names into snakecase
brfss_smart2010 =
  brfss_smart2010 |> 
  janitor::clean_names()
```

* focus on the “Overall Health” topic

```{r}
#Filter responses where topic == "OVerall Health Only"
brfss_overall_health =
  brfss_smart2010 |> 
  filter(topic == "Overall Health")

# brfss_overall_health |>
#   group_by(response) |> 
#   count()
```

* include only responses from “Excellent” to “Poor”:

```{r}
#Filter to include only responses that contain "Excellent", "Very good", "Good", "Fair", "Poor"
brfss_overall_health = 
  brfss_overall_health |> 
  filter(response == "Poor" | 
           response == "Fair" | 
           response == "Good" | 
           response == "Very good" | 
           response == "Excellent"
         )
```


* organize responses as a factor taking levels ordered from “Poor” to “Excellent”:

```{r}
#Convert variable type from char to factor
brfss_overall_health =
  brfss_overall_health |> 
  mutate(response = factor(
    response, 
    #we define the levels to have the 5 response types.
    levels = c ("Poor", "Fair", "Good", "Very good", "Excellent"), 
    #the categorical variable "response" is ordered so we indicate it as so
    ordered = TRUE)
    )
  
```

### Using this dataset, do or answer the following:

In 2002, which states were observed at 7 or more locations? What about in 2010?

```{r}
state20027cnt = 
  brfss_overall_health |> 
  filter(year == 2002) |>   #filter to include responses in 2002 only
  group_by(locationabbr) |>  #group by the state abbreviations
  summarize(num = n()) |>    #summarize the different response types 
  mutate(num = num/5) |>     #we know that there are 5 responses per location so we can get the number by                                   dividing
  arrange(desc(num))         #arrange by descending order for viewing ease

#output a table that shows stsates that have more than 7 locations and a state that had 6
state20027cnt |> 
  head(7) |> 
  knitr::kable(digits = 2)
```

* In 2002, PA, MA, NJ, CT, FL, and NC were states that were observed at 7 or more locations

```{r}
state20107cnt = 
  brfss_overall_health |> 
  filter(year == 2010) |>   #filter to include responses in 2010 only
  group_by(locationabbr) |>  #group by the state abbreviations
  summarize(num = n()) |>    #summarize the different response types 
  mutate(num = num/5) |>     #we know that there are 5 responses per location so we can get the number by                                   dividing
  arrange(desc(num))         #arrange by descending order for viewing ease

#output a table that shows stsates that have more than 7 locations and a state that had 6
state20107cnt |>
  head(15) |> 
  knitr::kable(digits = 2)
```

* In 2010, FL, NJ, TX, CA, MD, NC, NE, WA, MA, NY, OH, CO, PA, and SC, were states that were observed at 7 or more locations.

### Construct a dataset that is limited to...
Excellent responses, and contains, year, state, and a variable that averages the `data_value` across locations within a state. Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).

```{r}
brfss_avg = 
  brfss_overall_health |> 
  select(year, locationabbr, response, data_value) |>
  filter(response == "Excellent") |> 
  group_by(year, locationabbr) |> 
  summarize(mean_data = mean(data_value, na.rm = TRUE))

brfss_avg |> 
  ggplot(aes(x = year, y = mean_data)) + 
  geom_line(aes(color = locationabbr), alpha = .5)
```

### Make a two-panel plot showing...
for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

```{r}
#NY in 2006
brfssNY2006 =
  brfss_overall_health |> 
  filter(year == 2006) |> 
  filter(locationabbr == "NY")

#Plot
brfssNY2006plot = 
  brfssNY2006 |> 
  ggplot(aes(x = response, y = data_value, color = locationdesc)) +
  geom_point()

#NY in 2010
brfssNY2010 =
  brfss_overall_health |> 
  filter(year == 2010) |> 
  filter(locationabbr == "NY")

brfssNY2010plot =
  brfssNY2010 |> 
  ggplot(aes(x = response, y = data_value, color = locationdesc)) +
  geom_point()

brfssNY2006plot + brfssNY2010plot
```

# Problem 3

```{r}
#Import data + clean

#Retains the variable labels/details
demo_raw = 
  read_csv("./data/nhanes_covar.csv") |> 
  janitor::clean_names()


demo = 
  read_csv("./data/nhanes_covar.csv", skip = 4) |> 
  janitor::clean_names()
accel = 
  read_csv("./data/nhanes_accel.csv") |> 
  janitor::clean_names()
```

## Load, tidy, merge, and otherwise organize the data sets.

Your final dataset should include all originally observed variables; exclude participants less than 21 years of age, and those with missing demographic data; and encode data with reasonable variable classes (i.e. not numeric, and using factors with the ordering of tables and plots in mind).

```{r}
#Tidy 

## Tidy Accel (Long)
accel_wide = 
  accel |> 
  pivot_longer(
    min1:min1440,
    names_to = "minuteofday", 
    values_to = "mimsaccel",
    names_prefix = "min")
```
* We tidy accel in order to allow it to merge with demo data.

```{r}
## Filter Demo
demo_filter =
  demo |>
  
  #Filter
  filter(age >= 21) |> #keep those that are 21 y/o or older
  filter(!is.na(education)) |> #filter out missing demograph (education) data
  filter(!is.na(sex)) |> 
  
  #Factor - Education
  mutate(education = factor(
    education, 
    #we define the levels to have 3 education categories
    levels = c (1, 2, 3), 
    #the categorical variable "education" is ordered so we indicate it as so
    ordered = TRUE)
    ) |> 
  
  #Factor - Gender
  mutate(sex = factor(
    sex,
    levels = c (1,2),
    ordered = TRUE)
  )
```
* Filter out <21 y/o and missing demographic (eduation) variables
* Apply factors to categorical variables, sex and education.

```{r}
#Merge
accel_demo =
  left_join(demo_filter, accel_wide, by = "seqn") |> 
  
  #Factor - minsofday (It is like a short continuous but I Just store in factors because it's ordered)
  mutate(minuteofday = factor(
    minuteofday,
    levels = c(1:1440),
    ordered = TRUE)
  )
```


## Produce a reader-friendly table...
for the number of men and women in each education category, and create a visualization of the age distributions for men and women in each education category. Comment on these items.

```{r}
#Clean Data
men_women_edu = 
  demo_filter |> 
  group_by(education) |> 
  count(sex)

#Plot
  men_women_edu |> 
  ggplot(aes(x = education, y = n, color = sex)) +
  geom_point()
```

## Traditional analyses of accelerometer data focus on the total activity over the day. 
Using your tidied dataset, aggregate across minutes to create a total activity variable for each participant. Plot these total activities (y-axis) against age (x-axis); your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. Comment on your plot.

```{r}
#Clean Data
total_activity = 
  accel_demo |> 
  group_by(seqn,age, education, sex) |> 
  summarize(sum_mim = sum(mimsaccel))

#plot
#Separate into 3 Education GRoups (in order to plot panels)
education1 = 
  total_activity |> 
  filter(education == 1) |> 
  ggplot(aes(x = age, y = sum_mim, color = sex)) +
  geom_point() +
  geom_smooth(se = FALSE)

education2 =
  total_activity |> 
  filter(education == 2) |> 
  ggplot(aes(x = age, y = sum_mim, color = sex)) +
  geom_point() +
  geom_smooth(se = FALSE)

education3 = 
  total_activity |> 
  filter(education == 3) |> 
  ggplot(aes(x = age, y = sum_mim, color = sex)) +
  geom_point() +
  geom_smooth(se = FALSE)

education1 + education2 + education3
```

* For all 3 education groups there is an overall decreasing trend in total accelerometer activity as age increases. 

* For education groups 2 and 3, it seems like the total accerometer activity in females is a bit higher than males 

## Make a three-panel plot...
that shows the 24-hour activity time courses for each education level and use color to indicate sex. Describe in words any patterns or conclusions you can make based on this graph; including smooth trends may help identify differences.

```{r}
#Clean Data
accel_overtime = 
  accel_demo |> 
  group_by(minuteofday, education, sex) |> 
  summarize(mean_min = mean(mimsaccel))



#plot data
edu1time = 
  accel_overtime |> 
  filter(education == 1) |> 
  ggplot(aes(x = minuteofday, y = mean_min, color = sex)) +
  geom_point() + 
  geom_smooth(se = FALSE)

edu2time = 
  accel_overtime |> 
  filter(education == 2) |> 
  ggplot(aes(x = minuteofday, y = mean_min, color = sex)) +
  geom_point() +
  geom_smooth(se = FALSE)

edu3time = 
  accel_overtime |> 
  filter(education == 3) |> 
  ggplot(aes(x = minuteofday, y = mean_min, color = sex)) + 
  geom_point() +
  geom_smooth(se = FALSE)

edu1time + edu2time + edu3time
```


